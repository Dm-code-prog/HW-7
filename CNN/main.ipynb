{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _file(file):\n",
    "    file = open(file, \"r\", encoding=\"utf-8\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def clean_text(text, stops):\n",
    "\tres = ''.join(re.findall(r'[a-zA-z]| ', text))\n",
    "\ttokens = [i.lower() for i in res.split() if i not in stops]\n",
    "\treturn ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what disappointment admittedly best prequels s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this pale imitation die hard franchise sucks t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this goodguyvstheeviltyrant story set th centu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>this documentary i came across chance uk tv ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>this installment masters horror terrible appar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>horrible script apparently directed byno the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>five years tenko survivors returning home mari...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>i dont understand not critic evaluating qualit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>this movie pretentious foppish right funny the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>this movie truly amazingover years i acquired ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  answer\n",
       "0          0  what disappointment admittedly best prequels s...       0\n",
       "1          1  this pale imitation die hard franchise sucks t...       0\n",
       "2          2  this goodguyvstheeviltyrant story set th centu...       0\n",
       "3          3  this documentary i came across chance uk tv ch...       1\n",
       "4          4  this installment masters horror terrible appar...       0\n",
       "...      ...                                                ...     ...\n",
       "24995  24995  horrible script apparently directed byno the m...       0\n",
       "24996  24996  five years tenko survivors returning home mari...       1\n",
       "24997  24997  i dont understand not critic evaluating qualit...       1\n",
       "24998  24998  this movie pretentious foppish right funny the...       0\n",
       "24999  24999  this movie truly amazingover years i acquired ...       0\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = stopwords.words()\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df['text'] = df['text'].apply(clean_text, args=(stops,))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df['text'].values\n",
    "label = df['answer'].values\n",
    "r_train, r_test, l_train, l_test = train_test_split(\n",
    "    review, label, test_size=0.01, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(r_train)\n",
    "data_train = tokenizer.texts_to_sequences(r_train)\n",
    "data_test = tokenizer.texts_to_sequences(r_test)\n",
    "v_size = len(tokenizer.word_index) + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max = 250\n",
    "data_train = pad_sequences(data_train, padding='post', maxlen=Max)\n",
    "data_test = pad_sequences(data_test, padding='post', maxlen=Max)\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 250, 200)          24008000  \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 246, 128)          128128    \n",
      "                                                                 \n",
      " global_max_pooling1d_18 (Gl  (None, 128)              0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,137,429\n",
      "Trainable params: 24,137,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Embedding(v_size, embedding_dim, input_length=Max),\n",
    "    layers.Conv1D(128, 5, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "825/825 - 481s - loss: 0.3713 - accuracy: 0.8317 - 481s/epoch - 583ms/step\n",
      "Epoch 2/5\n",
      "825/825 - 511s - loss: 0.1139 - accuracy: 0.9616 - 511s/epoch - 620ms/step\n",
      "Epoch 3/5\n",
      "825/825 - 489s - loss: 0.0132 - accuracy: 0.9975 - 489s/epoch - 592ms/step\n",
      "Epoch 4/5\n",
      "825/825 - 466s - loss: 0.0013 - accuracy: 1.0000 - 466s/epoch - 565ms/step\n",
      "Epoch 5/5\n",
      "825/825 - 501s - loss: 2.5333e-04 - accuracy: 1.0000 - 501s/epoch - 607ms/step\n",
      "8/8 - 1s - loss: 0.4025 - accuracy: 0.8760 - 646ms/epoch - 81ms/step\n",
      "Test accuracy: 0.8759999871253967\n"
     ]
    }
   ],
   "source": [
    "model.fit(data_train, l_train, epochs=5, verbose=2, batch_size=30)\n",
    "loss, accuracy = model.evaluate(data_test, l_test, verbose=2)\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "test_data = df_test['text'].values\n",
    "test_data = tokenizer.texts_to_sequences(test_data)\n",
    "test_data = pad_sequences(test_data, padding='post', maxlen=Max)\n",
    "predictions = model.predict(test_data)\n",
    "predictions = predictions.tolist()\n",
    "predictions = [round(i[0]) for i in predictions]\n",
    "df_test['answer'] = predictions\n",
    "del df_test['text']\n",
    "df_test.to_csv('result_CNN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a44ab53a1426dfc9cee852afd9317b0c502bc521de65252438b7b7d31820b2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
